{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Deep Learning\n",
    "## Project: Build a Digit Recognition Program\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 1: Design and Test a Model Architecture\n",
    "Design and implement a deep learning model that learns to recognize sequences of digits. Train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, you can for example limit yourself to sequences up to five digits, and use five classifiers on top of your deep network. You would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- Your model can be derived from a deep neural net or a convolutional network.\n",
    "- You could experiment sharing or not the weights between the softmax classifiers.\n",
    "- You can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Synthetic MNIST digit sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Attempting to download:', 'train-images-idx3-ubyte.gz')\n",
      "0%....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%....65%....70%....75%....80%....85%....90%....95%....100%\n",
      "Download Complete!\n",
      "('Found and verified', './mnist_data/train-images-idx3-ubyte.gz')\n",
      "('Attempting to download:', 'train-labels-idx1-ubyte.gz')\n",
      "0%..85%.\n",
      "Download Complete!\n",
      "('Found and verified', './mnist_data/train-labels-idx1-ubyte.gz')\n",
      "('Attempting to download:', 't10k-images-idx3-ubyte.gz')\n",
      "0%....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%....65%....70%....75%....80%....85%....90%....95%....100%\n",
      "Download Complete!\n",
      "('Found and verified', './mnist_data/t10k-images-idx3-ubyte.gz')\n",
      "('Attempting to download:', 't10k-labels-idx1-ubyte.gz')\n",
      "0%180%\n",
      "Download Complete!\n",
      "('Found and verified', './mnist_data/t10k-labels-idx1-ubyte.gz')\n",
      "Skipping extraction of mnist_data/train-images-idx3-ubyte.gz.\n",
      "Skipping extraction of mnist_data/train-labels-idx1-ubyte.gz.\n",
      "Skipping extraction of mnist_data/t10k-images-idx3-ubyte.gz.\n",
      "Skipping extraction of mnist_data/t10k-labels-idx1-ubyte.gz.\n",
      "Display sample train image: index: 20146 label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADAdJREFUeJzt3W2MHIV5wPH/E/cwiaECk2C5xCmhshoh1DrSyWkVlKZy\nQ4FGMpEqF7dK3ArF+ZBEjcSHIvKhfERVXoTUNpEpVkyVkiARhKXSRGBVQvQFcSDXmEDCixxhy/ic\nECm8CHPYTz/cEF3gdu58O7uzl+f/k063OzN7+2jlv2d3Z+8mMhNJ9byr7wEk9cP4paKMXyrK+KWi\njF8qyvilooxfKsr4paKMXyrqN8Z5Z+fE2jyXdeO8S6mU13mVN/JULGfboeKPiKuB24A1wL9k5q1t\n25/LOj4S24a5S0ktHskDy952xU/7I2IN8E/ANcDlwM6IuHylP0/SeA3zmn8r8GxmPp+ZbwDfAbZ3\nM5akURsm/kuAFxZcP9os+xURsTsiZiJiZo5TQ9ydpC6N/N3+zNyTmdOZOT3F2lHfnaRlGib+Y8Cm\nBdff3yyTtAoME/+jwOaI+GBEnANcD+zvZixJo7biQ32Z+WZEfAH4AfOH+vZm5pOdTSZppIY6zp+Z\n9wP3dzSLpDHy471SUcYvFWX8UlHGLxVl/FJRxi8VZfxSUcYvFWX8UlHGLxVl/FJRxi8VZfxSUcYv\nFWX8UlHGLxVl/FJRxi8VZfxSUcYvFWX8UlHGLxVl/FJRxi8VZfxSUcYvFWX8UlHGLxVl/FJRQ52l\nNyKOAC8Dp4E3M3O6i6Ekjd5Q8Tf+ODN/2sHPkTRGPu2Xiho2/gQejIjHImJ3FwNJGo9hn/ZfmZnH\nIuJi4IGIeDozH1q4QfOfwm6Ac3nPkHcnqStD7fkz81jzfRa4F9i6yDZ7MnM6M6enWDvM3Unq0Irj\nj4h1EXH+W5eBq4DDXQ0mabSGedq/Abg3It76Of+Wmd/vZCpJI7fi+DPzeeD3O5xFPVhz0frW9df/\n16HW9X91/mzr+qfnTg3+2f94Y+ttf+sr/926XsPxUJ9UlPFLRRm/VJTxS0UZv1SU8UtFdfFbfVrF\nXtv6O63rd57/QOv6M0v8/A9NDf5U5x/9xWOtt33un9s/Dn7mtdeWuHe1cc8vFWX8UlHGLxVl/FJR\nxi8VZfxSUcYvFeVx/uJeuGrNULe/4uG/aV0/d2rwP7Efbbu99bYfu2dH6/rfvOa51vVq555fKsr4\npaKMXyrK+KWijF8qyvilooxfKsrj/BrKBf++rnX9Rf/x7MB1f3jdF1pvu2bwX/1ueJx/GO75paKM\nXyrK+KWijF8qyvilooxfKsr4paKWPM4fEXuBTwKzmXlFs2w98F3gUuAIsCMzfz66MTUqF3/o5FC3\nv+DHr7auP31y8M+/6Pbh7lvDWc6e/1vA1W9bdhNwIDM3Awea65JWkSXjz8yHgJfetng7sK+5vA+4\nruO5JI3YSl/zb8jM483lF4ENHc0jaUyGfsMvMxPIQesjYndEzETEzBxLflhb0pisNP4TEbERoPk+\nO2jDzNyTmdOZOT3F4JM2Shqvlca/H9jVXN4F3NfNOJLGZcn4I+Iu4H+A342IoxFxA3Ar8ImIeAb4\nk+a6pFVkyeP8mblzwKptHc+iHsw+/b7W9e/6vRjTJBo3P+EnFWX8UlHGLxVl/FJRxi8VZfxSUf7p\nbrU6M/iT21rl3PNLRRm/VJTxS0UZv1SU8UtFGb9UlPFLRXmcv7g1r/sru1W555eKMn6pKOOXijJ+\nqSjjl4oyfqko45eK8jh/cZu/ebR9g8+0r37lA+9pXX/e/57lQBob9/xSUcYvFWX8UlHGLxVl/FJR\nxi8VZfxSUUse54+IvcAngdnMvKJZdgvwWeBks9nNmXn/qIbU5Dr+Z2+0rt9895gG0Vlbzp7/W8DV\niyz/emZuab4MX1pllow/Mx8CXhrDLJLGaJjX/F+MiEMRsTciLuxsIkljsdL4vwFcBmwBjgNfHbRh\nROyOiJmImJnj1ArvTlLXVhR/Zp7IzNOZeQa4Hdjasu2ezJzOzOkp1q50TkkdW1H8EbFxwdVPAYe7\nGUfSuCznUN9dwMeB90bEUeDvgY9HxBYggSPA50Y4o6QRWDL+zNy5yOI7RjCLJtBUrGnfwD/7v2r5\nCT+pKOOXijJ+qSjjl4oyfqko45eK8k93q9Vcnm7fIMczh7rnnl8qyvilooxfKsr4paKMXyrK+KWi\njF8qyvilooxfKsr4paKMXyrK+KWijF8qyvilooxfKsr4paKMXyrK+KWijF8qyvilooxfKsr4paKM\nXypqyb/bHxGbgDuBDcz/lfY9mXlbRKwHvgtcChwBdmTmz0c3qibRB+5e4hTemljL2fO/CdyYmZcD\nfwB8PiIuB24CDmTmZuBAc13SKrFk/Jl5PDMfby6/DDwFXAJsB/Y1m+0DrhvVkJK6d1av+SPiUuDD\nwCPAhsw83qx6kfmXBZJWiWXHHxHnAfcAX8rMXyxcl5nJgLO2RcTuiJiJiJk5Tg01rKTuLCv+iJhi\nPvxvZ+b3msUnImJjs34jMLvYbTNzT2ZOZ+b0FGu7mFlSB5aMPyICuAN4KjO/tmDVfmBXc3kXcF/3\n40kaleWcovujwKeBJyLiYLPsZuBW4O6IuAH4CbBjNCNqlE5ffEHr+qloP5S39me+lFutlow/Mx8G\nYsDqbd2OI2lc/ISfVJTxS0UZv1SU8UtFGb9UlPFLRS3nOL9+jT3zl+ta18/l6TFNonFzzy8VZfxS\nUcYvFWX8UlHGLxVl/FJRxi8V5XH+4ta8Pui3tfXrzj2/VJTxS0UZv1SU8UtFGb9UlPFLRRm/VJTH\n+Yvb/M2j7Rt8ZjxzaPzc80tFGb9UlPFLRRm/VJTxS0UZv1SU8UtFLXmcPyI2AXcCG4AE9mTmbRFx\nC/BZ4GSz6c2Zef+oBtVo5Cuvtq7fdvjPW9e/u8thNFbL+ZDPm8CNmfl4RJwPPBYRDzTrvp6ZXxnd\neJJGZcn4M/M4cLy5/HJEPAVcMurBJI3WWb3mj4hLgQ8DjzSLvhgRhyJib0RcOOA2uyNiJiJm5jg1\n1LCSurPs+CPiPOAe4EuZ+QvgG8BlwBbmnxl8dbHbZeaezJzOzOkp1nYwsqQuLCv+iJhiPvxvZ+b3\nADLzRGaezswzwO3A1tGNKalrS8YfEQHcATyVmV9bsHzjgs0+BRzufjxJo7Kcd/s/CnwaeCIiDjbL\nbgZ2RsQW5g//HQE+N5IJNVKnf/ZS6/p3/2n7eq1ey3m3/2FgsT/u7jF9aRXzE35SUcYvFWX8UlHG\nLxVl/FJRxi8VZfxSUcYvFWX8UlHGLxVl/FJRxi8VZfxSUcYvFRWZOb47izgJ/GTBovcCPx3bAGdn\nUmeb1LnA2Vaqy9l+OzPft5wNxxr/O+48YiYzp3sboMWkzjapc4GzrVRfs/m0XyrK+KWi+o5/T8/3\n32ZSZ5vUucDZVqqX2Xp9zS+pP33v+SX1pJf4I+LqiPhRRDwbETf1McMgEXEkIp6IiIMRMdPzLHsj\nYjYiDi9Ytj4iHoiIZ5rvi54mrafZbomIY81jdzAiru1ptk0R8Z8R8cOIeDIi/rZZ3utj1zJXL4/b\n2J/2R8Qa4MfAJ4CjwKPAzsz84VgHGSAijgDTmdn7MeGI+BjwCnBnZl7RLPsH4KXMvLX5j/PCzPy7\nCZntFuCVvs/c3JxQZuPCM0sD1wF/TY+PXctcO+jhcetjz78VeDYzn8/MN4DvANt7mGPiZeZDwNvP\nmrEd2Ndc3sf8P56xGzDbRMjM45n5eHP5ZeCtM0v3+ti1zNWLPuK/BHhhwfWjTNYpvxN4MCIei4jd\nfQ+ziA3NadMBXgQ29DnMIpY8c/M4ve3M0hPz2K3kjNdd8w2/d7oyM7cA1wCfb57eTqScf802SYdr\nlnXm5nFZ5MzSv9TnY7fSM153rY/4jwGbFlx/f7NsImTmseb7LHAvk3f24RNvnSS1+T7b8zy/NEln\nbl7szNJMwGM3SWe87iP+R4HNEfHBiDgHuB7Y38Mc7xAR65o3YoiIdcBVTN7Zh/cDu5rLu4D7epzl\nV0zKmZsHnVmanh+7iTvjdWaO/Qu4lvl3/J8DvtzHDAPmugz4v+bryb5nA+5i/mngHPPvjdwAXAQc\nAJ4BHgTWT9Bs/wo8ARxiPrSNPc12JfNP6Q8BB5uva/t+7Frm6uVx8xN+UlG+4ScVZfxSUcYvFWX8\nUlHGLxVl/FJRxi8VZfxSUf8PqZKys8YOmFIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7f0ab16d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display sample test image: index: 9596 label: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb727318d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Generating Synthetic MNIST Data\n",
    "\n",
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "#%%\n",
    "\"\"\"\n",
    "\n",
    "# import modules\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import gzip\n",
    "import idx2numpy \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imsave\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from socket import socket\n",
    "\n",
    "# global variables\n",
    "\n",
    "idisplay = 1\n",
    "num_merge = 5\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "\n",
    "np.random.seed(133)\n",
    "\n",
    "# MNIST dataset\n",
    "mnist_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "\n",
    "#%%\n",
    "\n",
    "# download, extract and display sample images\n",
    "\n",
    "mnist_data = './mnist_data/'\n",
    "if not os.path.isdir(mnist_data):    \n",
    "    print ('Creating dir:', mnist_data)\n",
    "    os.mkdir(mnist_data)\n",
    "\n",
    "# reused/modified from tensorflow 1_notmnist.ipynb\n",
    "\n",
    "last_percent_reported = None\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(url, filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  \n",
    "  if force or not os.path.exists(filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url+filename, mnist_data+filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  \n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return mnist_data+filename\n",
    "\n",
    "mnist_train_images_gz = maybe_download(mnist_url, 'train-images-idx3-ubyte.gz', 9912422)\n",
    "mnist_train_labels_gz = maybe_download(mnist_url, 'train-labels-idx1-ubyte.gz', 28881)\n",
    "mnist_test_images_gz  = maybe_download(mnist_url, 't10k-images-idx3-ubyte.gz', 1648877)\n",
    "mnist_test_labels_gz  = maybe_download(mnist_url, 't10k-labels-idx1-ubyte.gz', 4542)\n",
    "\n",
    "def maybe_extract(filename):\n",
    "    fname = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    if os.path.isfile(fname):\n",
    "        print('Skipping extraction of %s.' % (filename))\n",
    "    else:\n",
    "        print('Extracting %s ...' % (filename))\n",
    "        cmd = 'gunzip {}'.format(filename)\n",
    "        os.system(cmd)\n",
    "    return fname\n",
    "\n",
    "maybe_extract('mnist_data/train-images-idx3-ubyte.gz')\n",
    "maybe_extract('mnist_data/train-labels-idx1-ubyte.gz')\n",
    "maybe_extract('mnist_data/t10k-images-idx3-ubyte.gz')\n",
    "maybe_extract('mnist_data/t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "train_samples = idx2numpy.convert_from_file('mnist_data/train-images-idx3-ubyte')\n",
    "train_labels  = idx2numpy.convert_from_file('mnist_data/train-labels-idx1-ubyte')\n",
    "test_samples  = idx2numpy.convert_from_file('mnist_data/t10k-images-idx3-ubyte')\n",
    "test_labels   = idx2numpy.convert_from_file('mnist_data/t10k-labels-idx1-ubyte')\n",
    "\n",
    "def display_samples(data, labels, text=None, num_samples=1, idx='rand', squeeze=0):\n",
    "    for i in range(num_samples):\n",
    "        if idx == 'rand':\n",
    "            idx = random.choice(range(data.shape[0]))\n",
    "\n",
    "        print 'Display sample {} image: index: {} label: {}'.format(text, idx, labels[idx])\n",
    "        if squeeze == 0:\n",
    "            plt.imshow(data[idx], interpolation='nearest')\n",
    "        else:\n",
    "            plt.imshow(np.squeeze(data[idx], axis=(2,)), interpolation='nearest')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "if idisplay:\n",
    "    display_samples(train_samples, train_labels, text='train', num_samples=1)\n",
    "    display_samples(test_samples, test_labels, text='test', num_samples=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display sample train image: index: 69290 label: [0 1 2 7 0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMTFhFboxxsSEVejGGBMTVqEbY0xM/D/Ecz9K3yPdnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb727287790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display sample test image: index: 16043 label: [ 0  4  1  4 10 10]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb727238610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def createSequences(data, labels, img_height, img_width, merge=5):\n",
    "    num_merged = int(data.shape[0]/merge)\n",
    "    nlabels = np.ndarray(shape=(data.shape[0]*2, merge+1), dtype=np.int32)\n",
    "    ndata = np.ndarray(shape=(data.shape[0]*2, img_height, img_width*merge), dtype=np.float32)\n",
    "    \n",
    "    for i in range(merge*2):\n",
    "        rand_idx = random.sample(range(0, data.shape[0]), data.shape[0])\n",
    "        w = 0; \n",
    "        for j in range(num_merged):\n",
    "            a, b, c, d, e = rand_idx[w:w+merge]\n",
    "            num_rand = random.choice(range(1,6))\n",
    "            zeros = np.zeros([28,28])\n",
    "            if num_rand == 5: \n",
    "                ndata[(i*num_merged)+j,:,:] = np.concatenate([data[a],data[b],data[c],data[d],data[e]], axis=1)\n",
    "                nlabels[(i*num_merged)+j,:] = np.hstack([0,labels[a],labels[b],labels[c],labels[d],labels[e]])\n",
    "            elif num_rand == 4:\n",
    "                ndata[(i*num_merged)+j,:,:] = np.concatenate([data[a],data[b],data[c],data[d],zeros], axis=1)\n",
    "                nlabels[(i*num_merged)+j,:] = np.hstack([0,labels[a],labels[b],labels[c],labels[d],10])\n",
    "            elif num_rand == 3:\n",
    "                ndata[(i*num_merged)+j,:,:] = np.concatenate([data[a],data[b],data[c],zeros,zeros], axis=1)\n",
    "                nlabels[(i*num_merged)+j,:] = np.hstack([0,labels[a],labels[b],labels[c],10,10])\n",
    "            elif num_rand == 2:\n",
    "                ndata[(i*num_merged)+j,:,:] = np.concatenate([data[a],data[b],zeros,zeros,zeros], axis=1)\n",
    "                nlabels[(i*num_merged)+j,:] = np.hstack([0,labels[a],labels[b],10,10,10])\n",
    "            elif num_rand == 1:\n",
    "                ndata[(i*num_merged)+j,:,:] = np.concatenate([data[a],zeros,zeros,zeros,zeros], axis=1)\n",
    "                nlabels[(i*num_merged)+j,:] = np.hstack([0,labels[a],10,10,10,10])\n",
    "            w += merge\n",
    "\n",
    "    # add dim for grey scale\n",
    "    ndata = np.expand_dims(ndata, axis=3)\n",
    "    \n",
    "    return ndata, nlabels\n",
    "    \n",
    "m_train_samples, m_train_labels = createSequences(train_samples, \n",
    "                                                  train_labels, \n",
    "                                                  img_height=img_height, \n",
    "                                                  img_width=img_width, \n",
    "                                                  merge=num_merge)\n",
    "\n",
    "m_test_samples, m_test_labels = createSequences(test_samples, \n",
    "                                                test_labels, \n",
    "                                                img_height=img_height, \n",
    "                                                img_width=img_width, \n",
    "                                                merge=num_merge)\n",
    "\n",
    "if idisplay:\n",
    "    display_samples(m_train_samples, m_train_labels, text='train', num_samples=1, squeeze=1)\n",
    "    display_samples(m_test_samples, m_test_labels, text='test', num_samples=1, squeeze=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Creating dir:', './mnist_merged/')\n",
      "Saving merged train images to: ./mnist_merged/merged_train ...\n",
      "Saving merged test images to: ./mnist_merged/merged_test ...\n",
      "Pickling data...\n",
      "Train samples: (114000, 28, 140, 1)\n",
      "Train labels: (114000, 6)\n",
      "Validation samples: (6000, 28, 140, 1)\n",
      "Validation labels: (6000, 6)\n",
      "Test samples: (20000, 28, 140, 1)\n",
      "Test labels: (20000, 6)\n",
      "Success!\n",
      "Compressed pickle size: 2198560464\n"
     ]
    }
   ],
   "source": [
    "mnist_merged = './mnist_merged/'\n",
    "mnist_merged_train = './mnist_merged/merged_train'\n",
    "mnist_merged_test  = './mnist_merged/merged_test'\n",
    "\n",
    "if not os.path.isdir(mnist_merged):    \n",
    "    print ('Creating dir:', mnist_merged)\n",
    "    os.mkdir(mnist_merged)\n",
    "    os.mkdir(mnist_merged_train)\n",
    "    os.mkdir(mnist_merged_test)\n",
    "\n",
    "print 'Saving merged train images to: {} ...'.format(mnist_merged_train)\n",
    "for i in range(m_train_samples.shape[0]):\n",
    "    save_file = '{}/{}.png'.format(mnist_merged_train, i)\n",
    "    imsave(save_file, (np.squeeze(m_train_samples[i], axis=(2,))))\n",
    "\n",
    "print 'Saving merged test images to: {} ...'.format(mnist_merged_test)\n",
    "for i in range(m_test_samples.shape[0]):\n",
    "    save_file = '{}/{}.png'.format(mnist_merged_test, i)\n",
    "    imsave(save_file, (np.squeeze(m_test_samples[i], axis=(2,))))\n",
    "\n",
    "if idisplay:\n",
    "    Image(filename='mnist_merged/merged_train/1.png')\n",
    "    Image(filename='mnist_merged/merged_test/1.png')\n",
    "\n",
    "# Save\n",
    "m_train_samples_save = m_train_samples\n",
    "m_train_labels_save = m_train_labels\n",
    "\n",
    "# Create validation set (6000 of 60000)\n",
    "nval = 6000\n",
    "m_val_samples = np.ndarray(shape=(nval, img_height, img_width*num_merge), dtype=np.float32)\n",
    "m_val_labels = np.ndarray(shape=(nval, num_merge), dtype=np.int32)\n",
    "\n",
    "m_val_samples = m_train_samples[:nval,]\n",
    "m_val_labels = m_train_labels[:nval,]\n",
    "m_train_samples = np.delete(m_train_samples, np.r_[:nval], 0)\n",
    "m_train_labels = np.delete(m_train_labels, np.r_[:nval], 0)\n",
    "\n",
    "# Create Pickling File\n",
    "print('Pickling data...')\n",
    "pickle_file = 'mnist_merged/MNIST.merged.pickle'\n",
    "\n",
    "print 'Train samples: {}'.format(m_train_samples.shape)\n",
    "print 'Train labels: {}'.format(m_train_labels.shape)\n",
    "print 'Validation samples: {}'.format(m_val_samples.shape)\n",
    "print 'Validation labels: {}'.format(m_val_labels.shape)\n",
    "print 'Test samples: {}'.format(m_test_samples.shape)\n",
    "print 'Test labels: {}'.format(m_test_labels.shape)\n",
    "\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    save = {\n",
    "        'm_train_samples': m_train_samples,\n",
    "        'm_train_labels': m_train_labels,\n",
    "        'm_val_samples': m_val_samples,\n",
    "        'm_val_labels': m_val_labels,\n",
    "        'm_test_samples': m_test_samples,\n",
    "        'm_test_labels': m_test_labels,\n",
    "        }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to {}: {}'.format(pickle_file, e))\n",
    "    raise\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Success!')\n",
    "print('Compressed pickle size: {}'.format(statinfo.st_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST : CNN Model to detect sequences up to 5 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST pickled data...\n",
      "Training data shape:  (114000, 28, 140, 1)\n",
      "Training label shape: (114000, 6)\n",
      "Validation data shape: (6000, 28, 140, 1)\n",
      "Validation label shape: (6000, 6)\n",
      "Test data shape:      (4000, 28, 140, 1)\n",
      "Test label shape:     (4000, 6)\n",
      "Data successfully loaded !!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jan 20 22:19:29 2017\n",
    "\n",
    "@author: harik\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\"\n",
    "    -------------------------------------------------------------------------------\n",
    "    CNN Model Architecture for multi digit recognition implemented with TensorFlow\n",
    "    -------------------------------------------------------------------------------\n",
    "      inputs    [batch_size, 28, 140, 1]\n",
    "      conv1     [patch=3x15, stride=1x1, padding=valid, 16 features]\n",
    "      relu1     [relu]\n",
    "      maxpool1  [patch=2x2, stride=2x2, padding=valid]\n",
    "      conv2     [patch=4x20, stride=1x1, padding=valid, 32 features]\n",
    "      relu2     [relu]\n",
    "      maxpool2  [patch=2x2, stride=2x2, padding=valid]\n",
    "      conv3     [patch=5x22, stride=1x1, padding=valid, 96 features]\n",
    "      relu2     [relu]\n",
    "      drop_out  10 %\n",
    "      fc        [nodes=64]\n",
    "      outputs   [y1,y2,y3,y4,y5]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#%%\n",
    "\n",
    "# program mode control\n",
    "\n",
    "debug     = 1\n",
    "idisplay  = 1\n",
    "svhn_en   = 0\n",
    "mnist_en  = 1\n",
    "restore_session = 0\n",
    "\n",
    "if mnist_en:\n",
    "    num_steps  = 7125\n",
    "    num_val    = 6000\n",
    "    num_tests  = 10000\n",
    "    img_width  = 140\n",
    "    img_height = 28\n",
    "    session_name = 'session/digit_recognizer.ckpt'\n",
    "    #session_name = 'save/session.mymodel.run2/digit_recognizer.mnist.ckpt'\n",
    "elif svhn_en:\n",
    "    num_steps  = 60000\n",
    "    num_val    = 5684\n",
    "    num_tests  = 13068\n",
    "    img_width  = 32\n",
    "    img_height = 32\n",
    "    session_name = 'save/session.mymodel.run2/digit_recognizer.svhn.ckpt'\n",
    "\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "if idisplay:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    from IPython.display import display\n",
    "\n",
    "if mnist_en:\n",
    "    print 'Loading MNIST pickled data...'\n",
    "    pickle_file = 'mnist_merged/MNIST.merged.pickle'\n",
    "    \n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        X_train_samples = save['m_train_samples']\n",
    "        y_train_samples = save['m_train_labels']\n",
    "        X_val_samples   = save['m_val_samples']\n",
    "        y_val_samples   = save['m_val_labels']\n",
    "        X_test_samples  = save['m_test_samples'][:4000,]\n",
    "        y_test_samples  = save['m_test_labels'][:4000,]\n",
    "        del save  \n",
    "        print 'Training data shape: ', X_train_samples.shape\n",
    "        print 'Training label shape:', y_train_samples.shape\n",
    "        print 'Validation data shape:', X_val_samples.shape\n",
    "        print 'Validation label shape:', y_val_samples.shape\n",
    "        print 'Test data shape:     ', X_test_samples.shape\n",
    "        print 'Test label shape:    ', y_test_samples.shape\n",
    "        print 'Data successfully loaded !!'\n",
    "elif svhn_en:\n",
    "    print 'Loading SVHN pickled data...'\n",
    "    pickle_file = 'svhn_data/SVHN.pickle'\n",
    "\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        X_train_samples = save['train_dataset']\n",
    "        y_train_samples = save['train_labels']\n",
    "        X_val_samples   = save['valid_dataset']\n",
    "        y_val_samples   = save['valid_labels']\n",
    "        X_test_samples  = save['test_dataset']\n",
    "        y_test_samples  = save['test_labels']\n",
    "        del save  \n",
    "        print 'Training data shape: ', X_train_samples.shape\n",
    "        print 'Training label shape:', y_train_samples.shape\n",
    "        print 'Validation data shape:', X_val_samples.shape\n",
    "        print 'Validation label shape:', y_val_samples.shape\n",
    "        print 'Test data shape:     ', X_test_samples.shape\n",
    "        print 'Test label shape:    ', y_test_samples.shape\n",
    "        print 'Data successfully loaded !!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display sample train image: 27069\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEKrQRUQS4v8BNizcOkJQcu0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb72714b550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display sample test image: 2877\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGxlnOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7466e3510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if idisplay:\n",
    "    def display_samples(num_samples=1):\n",
    "        for i in range(num_samples):        \n",
    "            # train samples\n",
    "            idx = random.choice(range(X_train_samples.shape[0]))\n",
    "            print 'Display sample train image:', idx\n",
    "            plt.imshow(X_train_samples[idx].reshape(img_height,img_width), interpolation='nearest')\n",
    "            plt.show()\n",
    "\n",
    "            # test samples\n",
    "            idx = random.choice(range(X_test_samples.shape[0]))\n",
    "            print 'Display sample test image:', idx\n",
    "            plt.imshow(X_test_samples[idx].reshape(img_height,img_width), interpolation='nearest')\n",
    "            plt.show()\n",
    "\n",
    "    display_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final image size after convolutions: 1 x 1\n",
      "Graph done!\n"
     ]
    }
   ],
   "source": [
    "if mnist_en:\n",
    "\n",
    "    # params\n",
    "    in_chan    = 1         # grey scale\n",
    "    batch_size = 16        # batch size\n",
    "\n",
    "    # conv1\n",
    "    c1_patch_h = 3         # patch size 3x15\n",
    "    c1_patch_w = 15        # patch size 3x15\n",
    "    c1_depth   = 16        # 16 features (out channels)\n",
    "    c1_padding = 'VALID' # padding valid\n",
    "    c1_stride  = [1,1,1,1] # stride 1x1\n",
    "\n",
    "    # maxpool1\n",
    "    p1_padding = 'VALID'   # padding valid\n",
    "    p1_patch   = [1,2,2,1] # patch size 2x2\n",
    "    p1_stride  = [1,2,2,1] # stride 2x2\n",
    "    \n",
    "    # conv2\n",
    "    c2_patch_h = 4         # patch size 4x20\n",
    "    c2_patch_w = 20        # patch size 4x20\n",
    "    c2_depth   = 32        # 32 features (out channels)\n",
    "    c2_padding = 'VALID'   # padding valid\n",
    "    c2_stride  = [1,1,1,1] # stride 1x1\n",
    "\n",
    "    # maxpool2\n",
    "    p2_padding = 'VALID'   # padding valid\n",
    "    p2_patch   = [1,2,2,1] # patch size 2x2\n",
    "    p2_stride  = [1,2,2,1] # stride 2x2\n",
    "\n",
    "    # conv3\n",
    "    c3_patch_h = 5         # patch size 5x22\n",
    "    c3_patch_w = 22        # patch size 5x22\n",
    "    c3_depth   = 96        # 96 features (out channels)\n",
    "    c3_padding = 'VALID'   # padding valid\n",
    "    c3_stride  = [1,1,1,1] # stride 1x1\n",
    "\n",
    "    # fc\n",
    "    keep_prob  = 0.9       # dropout rate\n",
    "    fc_nodes   = 64        # hidden layer\n",
    "\n",
    "    # output\n",
    "    out_digits = 6         # up to 5 digits [1-5]\n",
    "    out_labels = 11        # detect 0-9 & none\n",
    "\n",
    "elif svhn_en:\n",
    "    \n",
    "    # params\n",
    "    in_chan    = 1         # grey scale\n",
    "    batch_size = 16        # batch size\n",
    "\n",
    "    # conv1\n",
    "    c1_patch_h = 5         # patch size 5x5\n",
    "    c1_patch_w = 5         # patch size 5x5\n",
    "    c1_depth   = 16        # 16 features (out channels)\n",
    "    c1_padding = 'VALID'   # padding valid\n",
    "    c1_stride  = [1,1,1,1] # stride 1x1\n",
    "\n",
    "    # maxpool1\n",
    "    p1_padding = 'VALID'   # padding valid\n",
    "    p1_patch   = [1,2,2,1] # patch size 2x2\n",
    "    p1_stride  = [1,2,2,1] # stride 2x2\n",
    "    \n",
    "    # conv2\n",
    "    c2_patch_h = 5         # patch size 5x5\n",
    "    c2_patch_w = 5         # patch size 5x5\n",
    "    c2_depth   = 32        # 32 features (out channels)\n",
    "    c2_padding = 'VALID'   # padding valid\n",
    "    c2_stride  = [1,1,1,1] # stride 1x1\n",
    "\n",
    "    # maxpool2\n",
    "    p2_padding = 'VALID'   # padding valid\n",
    "    p2_patch   = [1,2,2,1] # patch size 2x2\n",
    "    p2_stride  = [1,2,2,1] # stride 2x2\n",
    "\n",
    "    # conv3\n",
    "    c3_patch_h = 5         # patch size 5x5\n",
    "    c3_patch_w = 5         # patch size 5x5\n",
    "    c3_depth   = 96        # 96 features (out channels)\n",
    "    c3_padding = 'VALID'   # padding valid\n",
    "    c3_stride  = [1,1,1,1] # stride 1x1\n",
    "\n",
    "    # fc\n",
    "    keep_prob  = 0.8       # dropout rate\n",
    "    fc_nodes   = 64        # hidden layer\n",
    "\n",
    "    # output\n",
    "    out_digits = 6         # up to 5 digits [1-5]\n",
    "    out_labels = 11        # detect 0-9 & none\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "\n",
    "    # in, out place holders\n",
    "\n",
    "    X_val  = tf.constant(X_val_samples)\n",
    "    X_test = tf.constant(X_test_samples)\n",
    "\n",
    "    Y = tf.placeholder(tf.int32, shape=(batch_size, out_digits))\n",
    "    X = tf.placeholder(tf.float32, shape=(batch_size, img_height, img_width, in_chan))\n",
    "\n",
    "    # weights & biases\n",
    "\n",
    "    def init_bias(name, shape):\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        return tf.get_variable(shape=shape, name=name, initializer=initializer)\n",
    "\n",
    "    def init_weight(name, shape):\n",
    "        initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "        return tf.get_variable(shape=shape, name=name, initializer=initializer)\n",
    "\n",
    "    # pool_out = [(width or height) - patch]/(stride) + 1 \n",
    "    # conv_out = [(width or height) - patch + 2 * pad]/(stride) + 1 \n",
    "    def calc_out(w, h, p_w, p_h, stride, padding, type='conv'):\n",
    "        pad = 1 if padding == 'SAME' else 0\n",
    "        if type == 'pool':\n",
    "            w_out = (w - p_w)/(stride) + 1\n",
    "            h_out = (h - p_h)/(stride) + 1\n",
    "        else:\n",
    "            w_out = (w - p_w + 2 * pad)/(stride) + 1\n",
    "            h_out = (h - p_h + 2 * pad)/(stride) + 1\n",
    "\n",
    "        return w_out, h_out\n",
    "\n",
    "    def calc_fc_size(im_w, im_h):\n",
    "        (c1_w, c1_h) = calc_out(im_w, im_h, c1_patch_w,  c1_patch_h,  c1_stride[1], c1_padding, type='conv')\n",
    "        (p1_w, p1_h) = calc_out(c1_w, c1_h, p1_patch[1], p1_patch[1], p1_stride[1], p1_padding, type='pool')\n",
    "        (c2_w, c2_h) = calc_out(p1_w, p1_h, c2_patch_w,  c2_patch_h,  c2_stride[1], c2_padding, type='conv')\n",
    "        (p2_w, p2_h) = calc_out(c2_w, c2_h, p2_patch[1], p2_patch[1], p2_stride[1], p2_padding, type='pool')\n",
    "        (c3_w, c3_h) = calc_out(p2_w, p2_h, c3_patch_w,  c3_patch_h,  c3_stride[1], c3_padding, type='conv')\n",
    "\n",
    "        print('Final image size after convolutions: {} x {}'.format(c3_w, c3_h))\n",
    "        return c3_w, c3_h\n",
    "\n",
    "    fc_w, fc_h = calc_fc_size(img_width, img_height)\n",
    "\n",
    "    b_C1 = init_bias(name='b_C1', shape=[c1_depth])\n",
    "    b_C2 = init_bias(name='b_C2', shape=[c2_depth])\n",
    "    b_C3 = init_bias(name='b_C3', shape=[c3_depth])\n",
    "    b_FC = init_bias(name='b_FC', shape=[fc_nodes])\n",
    "        \n",
    "    W_C1 = init_weight(name='W_C1', shape=[c1_patch_h, c1_patch_w, in_chan,  c1_depth])\n",
    "    W_C2 = init_weight(name='W_C2', shape=[c2_patch_h, c2_patch_w, c1_depth, c2_depth])\n",
    "    W_C3 = init_weight(name='W_C3', shape=[c3_patch_h, c3_patch_w, c2_depth, c3_depth])\n",
    "    W_FC = init_weight(name='W_FC', shape=[fc_w * fc_h * c3_depth, fc_nodes])\n",
    "        \n",
    "    b_Y1 = init_bias(name='b_Y1', shape=[out_labels])\n",
    "    b_Y2 = init_bias(name='b_Y2', shape=[out_labels])\n",
    "    b_Y3 = init_bias(name='b_Y3', shape=[out_labels])\n",
    "    b_Y4 = init_bias(name='b_Y4', shape=[out_labels])\n",
    "    b_Y5 = init_bias(name='b_Y5', shape=[out_labels])\n",
    "        \n",
    "    W_Y1 = init_weight(name='W_Y1', shape=[fc_nodes, out_labels])\n",
    "    W_Y2 = init_weight(name='W_Y2', shape=[fc_nodes, out_labels])\n",
    "    W_Y3 = init_weight(name='W_Y3', shape=[fc_nodes, out_labels])\n",
    "    W_Y4 = init_weight(name='W_Y4', shape=[fc_nodes, out_labels])\n",
    "    W_Y5 = init_weight(name='W_Y5', shape=[fc_nodes, out_labels])\n",
    "        \n",
    "    # CNN Model\n",
    "    def model(data, keep_prob):\n",
    "        with tf.name_scope('layer_1'):\n",
    "            c1_out = tf.nn.conv2d(data, W_C1, c1_stride, padding=c1_padding)\n",
    "            r1_out = tf.nn.relu(c1_out + b_C1)\n",
    "            p1_out = tf.nn.max_pool(r1_out, p1_patch, p1_stride, padding=p1_padding)\n",
    "        \n",
    "        with tf.name_scope('layer_2'):\n",
    "            c2_out = tf.nn.conv2d(p1_out, W_C2, c2_stride, padding=c2_padding)\n",
    "            r2_out = tf.nn.relu(c2_out + b_C2)\n",
    "            p2_out = tf.nn.max_pool(r2_out, p2_patch, p2_stride, padding=p2_padding)\n",
    "        \n",
    "        with tf.name_scope('layer_3'):\n",
    "            c3_out = tf.nn.conv2d(p2_out, W_C3, c3_stride, padding=c3_padding)\n",
    "            r3_out = tf.nn.relu(c3_out + b_C3)\n",
    "            d1_out = tf.nn.dropout(r3_out, keep_prob)\n",
    "        \n",
    "        with tf.name_scope('fc_layer'):\n",
    "            shape   = d1_out.get_shape().as_list()\n",
    "            reshape = tf.reshape(d1_out, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "            fc_out  = tf.nn.relu(tf.matmul(reshape, W_FC) + b_FC)\n",
    "        \n",
    "        with tf.name_scope('softmax'):                \n",
    "            y1 = tf.matmul(fc_out, W_Y1) + b_Y1\n",
    "            y2 = tf.matmul(fc_out, W_Y2) + b_Y2\n",
    "            y3 = tf.matmul(fc_out, W_Y3) + b_Y3\n",
    "            y4 = tf.matmul(fc_out, W_Y4) + b_Y4\n",
    "            y5 = tf.matmul(fc_out, W_Y5) + b_Y5\n",
    "\n",
    "        return [y1, y2, y3, y4, y5]\n",
    "\n",
    "    # Loss function: cross_entropy \n",
    "    [y1, y2, y3, y4, y5] = model(X, keep_prob)\n",
    "\n",
    "    with tf.name_scope(\"cross_entropy\"):        \n",
    "        cross_entropy = \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y1, Y[:, 1])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y2, Y[:, 2])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y3, Y[:, 3])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y4, Y[:, 4])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y5, Y[:, 5]))\n",
    "        tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
    "\n",
    "    # Optimizer\n",
    "    alpha = 0.05; learn_step = tf.Variable(0)\n",
    "    learn = tf.train.exponential_decay(alpha, learn_step, 10000, 0.96)\n",
    "    optimizer = tf.train.AdagradOptimizer(learn).minimize(cross_entropy, global_step=learn_step)\n",
    "\n",
    "    def softmax_combine(data):\n",
    "        y = tf.pack([\n",
    "            tf.nn.softmax(model(data, 1.0)[0]),\n",
    "            tf.nn.softmax(model(data, 1.0)[1]),\n",
    "            tf.nn.softmax(model(data, 1.0)[2]),\n",
    "            tf.nn.softmax(model(data, 1.0)[3]),\n",
    "            tf.nn.softmax(model(data, 1.0)[4])])\n",
    "        return y\n",
    "\n",
    "    y_pred      = softmax_combine(X)\n",
    "    y_val_pred  = softmax_combine(X_val)\n",
    "    y_test_pred = softmax_combine(X_test)\n",
    "\n",
    "    # Save\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # weight histogram\n",
    "    tf.summary.histogram(\"W_C1\", W_C1)\n",
    "    tf.summary.histogram(\"W_C2\", W_C2)\n",
    "    tf.summary.histogram(\"W_C3\", W_C3)\n",
    "    tf.summary.histogram(\"W_FC\", W_FC)\n",
    "    tf.summary.histogram(\"W_Y1\", W_Y1)\n",
    "    tf.summary.histogram(\"W_Y2\", W_Y2)\n",
    "    tf.summary.histogram(\"W_Y3\", W_Y3)\n",
    "    tf.summary.histogram(\"W_Y4\", W_Y4)\n",
    "    tf.summary.histogram(\"W_Y5\", W_Y5)\n",
    "\n",
    "    tf.summary.histogram(\"b_C1\", b_C1)\n",
    "    tf.summary.histogram(\"b_C2\", b_C2)\n",
    "    tf.summary.histogram(\"b_C3\", b_C3)\n",
    "    tf.summary.histogram(\"b_FC\", b_FC)\n",
    "    tf.summary.histogram(\"b_Y1\", b_Y1)\n",
    "    tf.summary.histogram(\"b_Y2\", b_Y2)\n",
    "    tf.summary.histogram(\"b_Y3\", b_Y3)\n",
    "    tf.summary.histogram(\"b_Y4\", b_Y4)\n",
    "    tf.summary.histogram(\"b_Y5\", b_Y5)\n",
    "\n",
    "    print('Graph done!')\n",
    "\n",
    "#%%\n",
    "\n",
    "def accuracy(predictions, labels, debug=0):\n",
    "    if debug:\n",
    "        for i in range(labels.shape[0]):\n",
    "            print 'Test i:', np.argmax(predictions, 2).T[i], labels[i]\n",
    "\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels)\n",
    "             / predictions.shape[1] / predictions.shape[0])\n",
    "\n",
    "def get_offset(step, batch_size, data):\n",
    "    offset = (step * batch_size) % (data.shape[0] - batch_size)\n",
    "    return offset\n",
    "\n",
    "def model_loop(X_samples, y_samples, num_steps=1, debug=0):\n",
    "    for step in range(num_steps):\n",
    "        offset  = get_offset(step, batch_size, y_samples)\n",
    "        batch_X = X_samples[offset:(offset + batch_size), :, :, :]\n",
    "        batch_Y = y_samples[offset:(offset + batch_size), :]        \n",
    "        feed_dict = {X: batch_X, Y: batch_Y}\n",
    "\n",
    "        _, loss, pred, summary = sess.run([optimizer, cross_entropy, y_pred, merged], feed_dict=feed_dict)\n",
    "\n",
    "        writer.add_summary(summary)\n",
    "\n",
    "        if (step % 250 == 0):\n",
    "            print (('step {}: loss -> {} accuracy -> {}%').format(step, round(loss,2), accuracy(pred, batch_Y[:,1:6], debug=debug)))\n",
    "            print (('Validation accuracy: {}%'.format(round(accuracy(y_val_pred.eval(), y_val_samples[:,1:6], debug=debug), 2))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Dont run this cell on normal machines. Logfile with the run on GoogleCloud is below\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    writer = tf.summary.FileWriter(\"log\", sess.graph)\n",
    "    merged = tf.summary.merge_all()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if restore_session:\n",
    "        print('Restoring session: ', session_name)\n",
    "        saver.restore(sess, session_name)\n",
    "    else:\n",
    "        # train loops\n",
    "        print ('Start training: batch_size {} num_steps {}').format(batch_size, num_steps)\n",
    "        model_loop(X_train_samples, y_train_samples, num_steps, debug=0)\n",
    "\n",
    "    # test accuracy\n",
    "    print ('Start Testing: num_tests {}').format(num_tests)\n",
    "    print (('Test accuracy: {}%'.format(accuracy(y_test_pred.eval(), y_test_samples[:,1:6], debug=debug))))\n",
    "\n",
    "    # save session\n",
    "    save_path = saver.save(sess, \"session/digit_recognizer.ckpt\")\n",
    "    print('Model saved to file: {}'.format(save_path))\n",
    "\n",
    "print('Tensorboard: tensorboard --logdir=log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dont run this cell above on normal machines. Logfile with the run on GoogleCloud is below\n",
    "\n",
    "Loading MNIST pickled data...\n",
    "\n",
    "Training data shape:  (114000, 28, 140, 1)\n",
    "\n",
    "Training label shape: (114000, 6)\n",
    "\n",
    "Validation data shape: (6000, 28, 140, 1)\n",
    "\n",
    "Validation label shape: (6000, 6)\n",
    "\n",
    "Test data shape:      (4000, 28, 140, 1)\n",
    "\n",
    "Test label shape:     (4000, 6)\n",
    "\n",
    "Data successfully loaded !!\n",
    "\n",
    "Final image size after convolutions: 1 x 1\n",
    "\n",
    "Graph done!\n",
    "\n",
    "Start training: batch_size 16 num_steps 7125\n",
    "\n",
    "step 0: loss -> 77.57 accuracy -> 1.25%\n",
    "\n",
    "Validation accuracy: 39.42%\n",
    "\n",
    "...............\n",
    "\n",
    "Validation accuracy: 89.86%\n",
    "\n",
    "step 6750: loss -> 1.53 accuracy -> 96.25%\n",
    "\n",
    "Validation accuracy: 89.74%\n",
    "\n",
    "step 7000: loss -> 2.46 accuracy -> 87.5%\n",
    "\n",
    "**Validation accuracy: 89.53%**\n",
    "\n",
    "Start Testing: num_tests 10000\n",
    "\n",
    "[ 8  4  2 10 10] [ 3  4  2 10 10]\n",
    "\n",
    "[ 9  6  4 10 10] [ 9  6  4 10 10]\n",
    "\n",
    "[ 0  3 10 10 10] [ 0  3 10 10 10]\n",
    "\n",
    "[3 5 0 7 7] [3 5 0 9 2]\n",
    "\n",
    "[ 4 10 10 10 10] [ 4 10 10 10 10]\n",
    "\n",
    "[ 3 10 10 10 10] [ 3 10 10 10 10]\n",
    "\n",
    "[1 9 3 7 7] [1 9 3 2 7]\n",
    "\n",
    "..................\n",
    "\n",
    "[ 3  4  6 10 10] [ 8  4  6 10 10]\n",
    "\n",
    "[ 9 10 10 10 10] [ 9 10 10 10 10]\n",
    "\n",
    "\n",
    "**Test accuracy: 90.695%**\n",
    "\n",
    "Model saved to file: session/digit_recognizer.ckpt\n",
    "\n",
    "Tensorboard: tensorboard --logdir=log\n",
    "\n",
    "\n",
    "#### Full logfile: submission/mnist.run.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "- Step1: Create synthetic data by concatenating up to 5 digits from MNIST dataset\n",
    "- Step2: Create pickle file with train, validation, and test samples\n",
    "- Step3: Load pickle files and display sample data for sanity\n",
    "- Step4: Use Tensor flow to create a CNN and train the model and compute validation accuracy\n",
    "- Step5: Run the model on test set and compute accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "    -------------------------------------------------------------------------------------\n",
    "    CNN Model Architecture for MNIST multi digit recognition implemented with TensorFlow\n",
    "    -------------------------------------------------------------------------------------\n",
    "      inputs    [batch_size, 28, 140, 1]\n",
    "      conv1     [patch=3x15, stride=1x1, padding=valid, 16 features]\n",
    "      relu1     [relu]\n",
    "      maxpool1  [patch=2x2, stride=2x2, padding=valid]\n",
    "      conv2     [patch=4x20, stride=1x1, padding=valid, 32 features]\n",
    "      relu2     [relu]\n",
    "      maxpool2  [patch=2x2, stride=2x2, padding=valid]\n",
    "      conv3     [patch=5x22, stride=1x1, padding=valid, 96 features]\n",
    "      relu2     [relu]\n",
    "      drop_out  10 %\n",
    "      fc        [nodes=64]\n",
    "      outputs   [y1,y2,y3,y4,y5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- Synthetic data by concatenating up to 5 digits from MNIST dataset. The generated data was used to train the model. Example synthetic images below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display sample train image: 16071\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7c1bda690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display sample test image: 1357\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN8aYkPgXRM4ck876JdIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7c1c24f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 2: Train a Model on a Realistic Dataset\n",
    "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare SVHN data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified train.tar.gz\n",
      "Found and verified test.tar.gz\n",
      "Found and verified extra.tar.gz\n",
      "Extracting data for train. This may take a while. Please wait.\n",
      "Extracting data for test. This may take a while. Please wait.\n",
      "Extracting data for extra. This may take a while. Please wait.\n",
      "Creating dictionary of bounding boxes...\n",
      "Successfully created dictionary of bounding boxes!\n",
      "Getting digit structure for training data...\n",
      "Success!\n",
      "Getting digit structure for test data...\n",
      "Success!\n",
      "Getting digit structure for extra data..."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Jan 21 11:05:22 2017\n",
    "\n",
    "@author: harik\n",
    "\"\"\"\n",
    "\n",
    "#%%\n",
    "\n",
    "# import modules \n",
    "\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import h5py\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(133)\n",
    "\n",
    "#%% \n",
    "\n",
    "# MNIST dataset\n",
    "\n",
    "# SVHN dataset \n",
    "svhn_url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "\n",
    "#%%\n",
    "\n",
    "# download, extract and display sample images\n",
    "\n",
    "svhn_data = './svhn_data/'\n",
    "if not os.path.isdir(svhn_data):    \n",
    "    print ('Creating dir:', svhn_data)\n",
    "    os.mkdir(svhn_data)\n",
    "\n",
    "# reused/modified from tensorflow 1_notmnist.ipynb\n",
    "\n",
    "last_percent_reported = None\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "\n",
    "def maybe_download(url, filename, expected_bytes, force=False):\n",
    "  \"\"\"Create dir if not present\"\"\"\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  \n",
    "  if force or not os.path.exists(filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url+filename, filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  \n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "svhn_train_filename = maybe_download(svhn_url, 'train.tar.gz', 404141560)\n",
    "svhn_test_filename = maybe_download(svhn_url, 'test.tar.gz', 276555967)\n",
    "svhn_extra_filename = maybe_download(svhn_url, 'extra.tar.gz', 1955489752)\n",
    "\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  global svhn_data\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(path=svhn_data)\n",
    "    tar.close()\n",
    "  return root\n",
    "  \n",
    "svhn_train_folder = 'svhn_data/' + maybe_extract(svhn_train_filename)\n",
    "svhn_test_folder  = 'svhn_data/' + maybe_extract(svhn_test_filename)\n",
    "svhn_extra_folder = 'svhn_data/' + maybe_extract(svhn_extra_filename)\n",
    "\n",
    "def display_samples(data_folder, num_samples=1):\n",
    "    for i in range(num_samples):\n",
    "        im_name = random.choice(os.listdir(data_folder))\n",
    "        im_file = data_folder + \"/\" + im_name\n",
    "        #display(Image(filename=im_file))\n",
    "\n",
    "#display_samples(svhn_train_folder)\n",
    "#display_samples(svhn_test_folder)\n",
    "#display_samples(svhn_extra_folder)\n",
    " \n",
    "#%%\n",
    "\n",
    "# resued/modified: from https://github.com/ritchieng/NumNum/NumNum/load_data.py\n",
    "\n",
    "# Create dictionary for bounding boxes\n",
    "print('Creating dictionary of bounding boxes...')\n",
    "class DigitStructFile:\n",
    "    def __init__(self, inf):\n",
    "        self.inf = h5py.File(inf, 'r')\n",
    "        self.digitStructName = self.inf['digitStruct']['name']\n",
    "        self.digitStructBbox = self.inf['digitStruct']['bbox']\n",
    "\n",
    "    def getName(self,n):\n",
    "        return ''.join([chr(c[0]) for c in self.inf[self.digitStructName[n][0]].value])\n",
    "\n",
    "    def bboxHelper(self,attr):\n",
    "        if (len(attr) > 1):\n",
    "            attr = [self.inf[attr.value[j].item()].value[0][0] for j in range(len(attr))]\n",
    "        else:\n",
    "            attr = [attr.value[0][0]]\n",
    "        return attr\n",
    "\n",
    "    def getBbox(self,n):\n",
    "        bbox = {}\n",
    "        bb = self.digitStructBbox[n].item()\n",
    "        bbox['height'] = self.bboxHelper(self.inf[bb][\"height\"])\n",
    "        bbox['label'] = self.bboxHelper(self.inf[bb][\"label\"])\n",
    "        bbox['left'] = self.bboxHelper(self.inf[bb][\"left\"])\n",
    "        bbox['top'] = self.bboxHelper(self.inf[bb][\"top\"])\n",
    "        bbox['width'] = self.bboxHelper(self.inf[bb][\"width\"])\n",
    "        return bbox\n",
    "    \n",
    "    def getDigitStructure(self,n):\n",
    "        s = self.getBbox(n)\n",
    "        s['name']=self.getName(n)\n",
    "        return s\n",
    "\n",
    "    def getAllDigitStructure(self):\n",
    "        return [self.getDigitStructure(i) for i in range(len(self.digitStructName))]\n",
    "\n",
    "    def getAllDigitStructure_ByDigit(self):\n",
    "        pictDat = self.getAllDigitStructure()\n",
    "        result = []\n",
    "        structCnt = 1\n",
    "        for i in range(len(pictDat)):\n",
    "            item = { 'filename' : pictDat[i][\"name\"] }\n",
    "            figures = []\n",
    "            for j in range(len(pictDat[i]['height'])):\n",
    "               figure = {}\n",
    "               figure['height'] = pictDat[i]['height'][j]\n",
    "               figure['label']  = pictDat[i]['label'][j]\n",
    "               figure['left']   = pictDat[i]['left'][j]\n",
    "               figure['top']    = pictDat[i]['top'][j]\n",
    "               figure['width']  = pictDat[i]['width'][j]\n",
    "               figures.append(figure)\n",
    "            structCnt = structCnt + 1\n",
    "            item['boxes'] = figures\n",
    "            result.append(item)\n",
    "        return result\n",
    "    \n",
    "print(\"Successfully created dictionary of bounding boxes!\")\n",
    "   \n",
    "# Get Digit Structure\n",
    "print('Getting digit structure for training data...')\n",
    "digitFileTrain=DigitStructFile(os.path.join(svhn_train_folder,'digitStruct.mat'))\n",
    "train_data=digitFileTrain.getAllDigitStructure_ByDigit()\n",
    "print('Success!')\n",
    "\n",
    "print('Getting digit structure for test data...')\n",
    "digitFileTest=DigitStructFile(os.path.join(svhn_test_folder,'digitStruct.mat'))\n",
    "test_data=digitFileTest.getAllDigitStructure_ByDigit()\n",
    "print('Success!')\n",
    "\n",
    "print('Getting digit structure for extra data...')\n",
    "digitFileExtra=DigitStructFile(os.path.join(svhn_extra_folder,'digitStruct.mat'))\n",
    "extra_data=digitFileExtra.getAllDigitStructure_ByDigit()\n",
    "print('Success!')\n",
    "\n",
    "# Crop Training Images\n",
    "print('Cropping training images...')\n",
    "train_imsize = np.ndarray([len(train_data),2])\n",
    "for i in np.arange(len(train_data)):\n",
    "    filename = train_data[i]['filename']\n",
    "    fullname = os.path.join(svhn_train_folder, filename)\n",
    "    im = Image.open(fullname)\n",
    "    train_imsize[i, :] = im.size[:]\n",
    "\n",
    "print('Success!')\n",
    "\n",
    "# Crop Test Images\n",
    "print('Cropping test images...')\n",
    "test_imsize = np.ndarray([len(test_data),2])\n",
    "for i in np.arange(len(test_data)):\n",
    "    filename = test_data[i]['filename']\n",
    "    fullname = os.path.join(svhn_test_folder, filename)\n",
    "    im = Image.open(fullname)\n",
    "    test_imsize[i, :] = im.size[:]\n",
    "\n",
    "print('Success!')\n",
    "\n",
    "# Crop Extra Images\n",
    "print('Cropping extra images...')\n",
    "extra_imsize = np.ndarray([len(extra_data),2])\n",
    "for i in np.arange(len(extra_data)):\n",
    "    filename = extra_data[i]['filename']\n",
    "    fullname = os.path.join(svhn_extra_folder, filename)\n",
    "    im = Image.open(fullname)\n",
    "    extra_imsize[i, :] = im.size[:]\n",
    "\n",
    "print('Success!')\n",
    "\n",
    "\n",
    "def generate_dataset(data, folder):\n",
    "    dataset = np.ndarray([len(data),32,32,1], dtype='float32')\n",
    "    labels = np.ones([len(data),6], dtype=int) * 10\n",
    "    for i in np.arange(len(data)):\n",
    "        filename = data[i]['filename']\n",
    "        fullname = os.path.join(folder, filename)\n",
    "        im = Image.open(fullname)\n",
    "        boxes = data[i]['boxes']\n",
    "        num_digit = len(boxes)\n",
    "        labels[i,0] = num_digit\n",
    "        top = np.ndarray([num_digit], dtype='float32')\n",
    "        left = np.ndarray([num_digit], dtype='float32')\n",
    "        height = np.ndarray([num_digit], dtype='float32')\n",
    "        width = np.ndarray([num_digit], dtype='float32')\n",
    "        for j in np.arange(num_digit):\n",
    "            if j < 5: \n",
    "                labels[i,j+1] = boxes[j]['label']\n",
    "                if boxes[j]['label'] == 10: labels[i,j+1] = 0\n",
    "            else: print('#',i,'image has more than 5 digits.')\n",
    "            top[j] = boxes[j]['top']\n",
    "            left[j] = boxes[j]['left']\n",
    "            height[j] = boxes[j]['height']\n",
    "            width[j] = boxes[j]['width']\n",
    "        \n",
    "        im_top = np.amin(top)\n",
    "        im_left = np.amin(left)\n",
    "        im_height = np.amax(top) + height[np.argmax(top)] - im_top\n",
    "        im_width = np.amax(left) + width[np.argmax(left)] - im_left\n",
    "        \n",
    "        im_top = int(np.floor(im_top - 0.1 * im_height))\n",
    "        im_left = int(np.floor(im_left - 0.1 * im_width))\n",
    "        im_bottom = int(np.amin([np.ceil(im_top + 1.2 * im_height), im.size[1]]))\n",
    "        im_right = int(np.amin([np.ceil(im_left + 1.2 * im_width), im.size[0]]))\n",
    "\n",
    "        im = im.crop((im_left, im_top, im_right, im_bottom)).resize([32,32], Image.ANTIALIAS)\n",
    "        im = np.dot(np.array(im, dtype='float32'), [[0.2989],[0.5870],[0.1140]])\n",
    "        mean = np.mean(im, dtype='float32')\n",
    "        std = np.std(im, dtype='float32', ddof=1)\n",
    "        if std < 1e-4: std = 1.\n",
    "        im = (im - mean) / std\n",
    "        dataset[i,:,:,:] = im[:,:,:]\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "print('Generating training dataset and labels...')\n",
    "train_dataset, train_labels = generate_dataset(train_data, svhn_train_folder)\n",
    "print('Success! \\n Training set: {} \\n Training labels: {}'.format(train_dataset.shape, train_labels.shape))\n",
    "\n",
    "print('Generating testing dataset and labels...')\n",
    "test_dataset, test_labels = generate_dataset(test_data, svhn_test_folder)\n",
    "print('Success! \\n Testing set: {} \\n Testing labels: {}'.format(test_dataset.shape, test_labels.shape))\n",
    "\n",
    "print('Generating extra dataset and labels...')\n",
    "extra_dataset, extra_labels = generate_dataset(extra_data, svhn_extra_folder)\n",
    "print('Success! \\n Testing set: {} \\n Testing labels: {}'.format(extra_dataset.shape, extra_labels.shape))\n",
    "\n",
    "# Clean up data by deleting digits more than 5 (very few)\n",
    "print('Cleaning up training data...')\n",
    "train_dataset = np.delete(train_dataset, 29929, axis=0)\n",
    "train_labels = np.delete(train_labels, 29929, axis=0)\n",
    "print('Success!')\n",
    "\n",
    "#%%\n",
    "# Expand Training Data\n",
    "print('Expanding training data randomly...')\n",
    "\n",
    "random.seed(8)\n",
    "\n",
    "n_labels = 10\n",
    "valid_index = []\n",
    "valid_index2 = []\n",
    "train_index = []\n",
    "train_index2 = []\n",
    "for i in np.arange(n_labels):\n",
    "    valid_index.extend(np.where(train_labels[:,1] == (i))[0][:400].tolist())\n",
    "    train_index.extend(np.where(train_labels[:,1] == (i))[0][400:].tolist())\n",
    "    valid_index2.extend(np.where(extra_labels[:,1] == (i))[0][:200].tolist())\n",
    "    train_index2.extend(np.where(extra_labels[:,1] == (i))[0][200:].tolist())\n",
    "\n",
    "random.shuffle(valid_index)\n",
    "random.shuffle(train_index)\n",
    "random.shuffle(valid_index2)\n",
    "random.shuffle(train_index2)\n",
    "\n",
    "valid_dataset = np.concatenate((extra_dataset[valid_index2,:,:,:], train_dataset[valid_index,:,:,:]), axis=0)\n",
    "valid_labels = np.concatenate((extra_labels[valid_index2,:], train_labels[valid_index,:]), axis=0)\n",
    "train_dataset_new = np.concatenate((extra_dataset[train_index2,:,:,:], train_dataset[train_index,:,:,:]), axis=0)\n",
    "train_labels_new = np.concatenate((extra_labels[train_index2,:], train_labels[train_index,:]), axis=0)\n",
    "\n",
    "print('Success! \\n Training set: {} \\n Training labels: {}'.format(train_dataset_new.shape, train_labels_new.shape))\n",
    "print('Success! \\n Validation set: {} \\n Validation labels: {}'.format(valid_dataset.shape, valid_labels.shape))\n",
    "print('Success! \\n Testing set: {} \\n Testing labels: {}'.format(test_dataset.shape, test_labels.shape))\n",
    "\n",
    "#%%\n",
    "\n",
    "# Create Pickling File\n",
    "print('Pickling data...')\n",
    "pickle_file = 'svhn_data/SVHN.pickle'\n",
    "\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    save = {\n",
    "        'train_dataset': train_dataset,\n",
    "        'train_labels': train_labels,\n",
    "        'valid_dataset': valid_dataset,\n",
    "        'valid_labels': valid_labels,\n",
    "        'test_dataset': test_dataset,\n",
    "        'test_labels': test_labels,\n",
    "        }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to {}: {}'.format(pickle_file, e))\n",
    "    raise\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Success!')\n",
    "print('Compressed pickle size: {}'.format(statinfo.st_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVHN: CNN Model to detect sequences up to 5 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
